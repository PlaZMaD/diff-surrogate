{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.51) detected. current: 1.0.55 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/shir994/physics-1d/a5602f0a41f84e04b1652096de7fdb83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "experiment = Experiment(project_name=\"physics_1d\", workspace=\"shir994\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "env: LIBRARY_PATH=/usr/local/cuda/lib64\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%env LIBRARY_PATH=/usr/local/cuda/lib64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\", 0)\n",
    "%matplotlib inline\n",
    "\n",
    "my_cmap = plt.cm.jet\n",
    "my_cmap.set_under('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"simple_surr.csv\", index_col=0)\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_px</th>\n",
       "      <th>start_py</th>\n",
       "      <th>start_pz</th>\n",
       "      <th>pid</th>\n",
       "      <th>hit_x</th>\n",
       "      <th>hit_y</th>\n",
       "      <th>hit_z</th>\n",
       "      <th>magn_len</th>\n",
       "      <th>start_theta</th>\n",
       "      <th>start_phi</th>\n",
       "      <th>start_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>0.168870</td>\n",
       "      <td>0.537594</td>\n",
       "      <td>8.433587</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-268.310394</td>\n",
       "      <td>147.968033</td>\n",
       "      <td>-13000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.066716</td>\n",
       "      <td>1.266435</td>\n",
       "      <td>8.452391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9789</th>\n",
       "      <td>0.082548</td>\n",
       "      <td>-0.288494</td>\n",
       "      <td>7.888186</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-120.654259</td>\n",
       "      <td>-84.459557</td>\n",
       "      <td>-13000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>-1.292109</td>\n",
       "      <td>7.893891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>0.044096</td>\n",
       "      <td>-0.029537</td>\n",
       "      <td>9.005111</td>\n",
       "      <td>13.0</td>\n",
       "      <td>605.092896</td>\n",
       "      <td>-8.966905</td>\n",
       "      <td>-13000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>-0.590197</td>\n",
       "      <td>9.005267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.332521</td>\n",
       "      <td>-0.517492</td>\n",
       "      <td>7.260886</td>\n",
       "      <td>13.0</td>\n",
       "      <td>185.995667</td>\n",
       "      <td>-163.875076</td>\n",
       "      <td>-13000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084515</td>\n",
       "      <td>-0.999667</td>\n",
       "      <td>7.286894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24355</th>\n",
       "      <td>-0.292245</td>\n",
       "      <td>-0.259529</td>\n",
       "      <td>5.190126</td>\n",
       "      <td>13.0</td>\n",
       "      <td>290.443329</td>\n",
       "      <td>-115.915115</td>\n",
       "      <td>-13000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.075164</td>\n",
       "      <td>-2.415417</td>\n",
       "      <td>5.204822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_px  start_py  start_pz   pid       hit_x       hit_y    hit_z  \\\n",
       "5779   0.168870  0.537594  8.433587 -13.0 -268.310394  147.968033 -13000.0   \n",
       "9789   0.082548 -0.288494  7.888186 -13.0 -120.654259  -84.459557 -13000.0   \n",
       "14250  0.044096 -0.029537  9.005111  13.0  605.092896   -8.966905 -13000.0   \n",
       "884    0.332521 -0.517492  7.260886  13.0  185.995667 -163.875076 -13000.0   \n",
       "24355 -0.292245 -0.259529  5.190126  13.0  290.443329 -115.915115 -13000.0   \n",
       "\n",
       "       magn_len  start_theta  start_phi   start_P  \n",
       "5779        5.0     0.066716   1.266435  8.452391  \n",
       "9789        2.0     0.038022  -1.292109  7.893891  \n",
       "14250      12.0     0.005894  -0.590197  9.005267  \n",
       "884         1.0     0.084515  -0.999667  7.286894  \n",
       "24355       4.0     0.075164  -2.415417  5.204822  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e8f24a1d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.start_theta.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = [\"hit_x\", \"hit_y\"]\n",
    "inputs_columns = [\"pid\", \"start_theta\", \"start_phi\", \"start_P\", \"magn_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor(df[data_columns].to_numpy(dtype=np.float32)).to(device)\n",
    "inputs = torch.Tensor(df[inputs_columns].to_numpy(dtype=np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, out_dim, hidden_dim=100, input_param=5):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(noise_dim + input_param, hidden_dim)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.constant_(self.fc1.bias, 0.0)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.constant_(self.fc2.bias, 0.0)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim, out_dim)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        nn.init.constant_(self.fc3.bias, 0.0)\n",
    "\n",
    "    def forward(self, z, params):\n",
    "        \"\"\"\n",
    "            Generator takes a vector of noise and produces sample\n",
    "        \"\"\"\n",
    "        #z = torch.cat([z, params.repeat(z.shape[0], 1)], dim=1)\n",
    "        z = torch.cat([z, params], dim=1)\n",
    "        h1 = torch.tanh(self.fc1(z))\n",
    "        h2 = F.leaky_relu(self.fc2(h1))\n",
    "        y_gen = self.fc3(h2)\n",
    "        return y_gen\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=100, input_param=2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_dim + input_param, hidden_dim)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.constant_(self.fc1.bias, 0.0)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "        nn.init.constant_(self.fc2.bias, 0.0)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        nn.init.constant_(self.fc3.bias, 0.0)\n",
    "        \n",
    "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
    "        nn.init.xavier_normal_(self.fc4.weight)\n",
    "        nn.init.constant_(self.fc4.bias, 0.0)\n",
    "\n",
    "    def forward(self, x, params):\n",
    "        x = torch.cat([x, params], dim=1)\n",
    "        h1 = torch.tanh(self.fc1(x))\n",
    "        h2 = F.leaky_relu(self.fc2(h1))\n",
    "        h3 = F.leaky_relu(self.fc3(h2))\n",
    "        score = torch.sigmoid(self.fc4(h3))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'TASK': 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"NOISE_DIM\": 50,\n",
    "    \"num_epochs\": 1000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"n_d_train\": 5,\n",
    "    \"INST_NOISE_STD\": 0.3,\n",
    "    \"INSTANCE_NOISE\": False,\n",
    "    \"param_dim\": 1,\n",
    "    \"x_dim\": 4\n",
    "}\n",
    "experiment.log_parameters(hyper_params)\n",
    "INSTANCE_NOISE = hyper_params['INSTANCE_NOISE']\n",
    "TASK = hyper_params['TASK']\n",
    "\n",
    "from gan import GANLosses\n",
    "from utils import iterate_minibatches\n",
    "PATH = \"./physics_gan.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(hyper_params['NOISE_DIM'], 2, hidden_dim=100,\n",
    "          input_param=hyper_params['param_dim'] + hyper_params['x_dim']).to(device)\n",
    "discriminator = Discriminator(in_dim=2, hidden_dim=100,\n",
    "              input_param=hyper_params['param_dim'] + hyper_params['x_dim']).to(device)\n",
    "\n",
    "g_optimizer = optim.Adam(generator.parameters(),     lr=hyper_params['learning_rate'], betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=hyper_params['learning_rate'], betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise(N, NOISE_DIM):\n",
    "    return np.random.normal(size=(N,NOISE_DIM)).astype(np.float32)\n",
    "\n",
    "def draw_hitmap(n_samples=100):\n",
    "    f = plt.figure(figsize=(21,16))\n",
    "    for index in range(16):\n",
    "        plt.subplot(4,4, index + 1)\n",
    "        theta = torch.empty(size=[n_samples,1]).uniform_(df.start_theta.min(), df.start_theta.max())\n",
    "        phi = torch.empty(size=[n_samples,1]).uniform_(df.start_phi.min(), df.start_phi.max())\n",
    "        p = torch.empty(size=[n_samples,1]).uniform_(df.start_P.min(), df.start_P.max())\n",
    "\n",
    "        pids = torch.distributions.Bernoulli(probs=0.5).sample([n_samples, 1])\n",
    "        pids[pids == 1] = 13.\n",
    "        pids[pids == 0] = -13.\n",
    "\n",
    "        magn_len = torch.empty(size=[1, 1], dtype=torch.float32).uniform_(1, 15).repeat([n_samples, 1])\n",
    "\n",
    "\n",
    "        noise = torch.Tensor(sample_noise(n_samples, hyper_params['NOISE_DIM'])).to(device)\n",
    "        distr = generator(noise, torch.cat([pids, theta, phi, p, magn_len], dim=1).to(device)).detach().cpu().numpy()\n",
    "\n",
    "        plt.hist2d(distr[:,0], distr[:, 1], bins=50, cmap=my_cmap, cmin=1e-10, normed=True)\n",
    "        plt.grid()\n",
    "        plt.colorbar()\n",
    "        plt.title(\"len={:.2f}\".format(magn_len[0,0].item()), fontsize=15)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "\n",
    "    # ===========================\n",
    "    # IMPORTANT PARAMETER:\n",
    "    # Number of D updates per G update\n",
    "    # ===========================\n",
    "    k_d, k_g = hyper_params[\"n_d_train\"], 1\n",
    "\n",
    "    gan_losses = GANLosses(TASK, device)\n",
    "\n",
    "    try:\n",
    "        with experiment.train():\n",
    "            for epoch in range(hyper_params['num_epochs']):\n",
    "                dis_epoch_loss = []\n",
    "                gen_epoch_loss = []\n",
    "\n",
    "                for input_data, inputs_batch in iterate_minibatches(data, hyper_params['batch_size'], y=inputs):\n",
    "                    # Optimize D\n",
    "                    for _ in range(k_d):\n",
    "                        # Sample noise\n",
    "                        noise = torch.Tensor(sample_noise(len(input_data), hyper_params['NOISE_DIM'])).to(device)\n",
    "\n",
    "                        # Do an update\n",
    "                        inp_data = input_data.to(device)\n",
    "                        data_gen = generator(noise, inputs_batch)\n",
    "\n",
    "                        if INSTANCE_NOISE:\n",
    "                            inp_data += torch.distributions.Normal(0,hyper_params['INST_NOISE_STD']).\\\n",
    "                                        sample(inp_data.shape).to(device)\n",
    "                            data_gen += torch.distributions.Normal(0, hyper_params['INST_NOISE_STD']).\\\n",
    "                                        sample(data_gen.shape).to(device)\n",
    "\n",
    "                        loss = gan_losses.d_loss(discriminator(data_gen, inputs_batch),\n",
    "                                                discriminator(inp_data, inputs_batch))\n",
    "                        if TASK == 4:\n",
    "                            grad_penalty = gan_losses.calc_gradient_penalty(discriminator,\n",
    "                                                                            data_gen.data,\n",
    "                                                                            inputs_batch.data,\n",
    "                                                                            inp_data.data)\n",
    "                            loss += grad_penalty\n",
    "\n",
    "                        if TASK == 5:\n",
    "                            grad_penalty = gan_losses.calc_zero_centered_GP(discriminator,\n",
    "                                                                            data_gen.data,\n",
    "                                                                            inputs_batch.data,\n",
    "                                                                            inp_data.data)\n",
    "                            loss -= grad_penalty                            \n",
    "\n",
    "                        d_optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        d_optimizer.step()\n",
    "\n",
    "                        if TASK == 3:                    \n",
    "                            for p in discriminator.parameters():\n",
    "                                p.data.clamp_(clamp_lower, clamp_upper)\n",
    "                    dis_epoch_loss.append(loss.item())\n",
    "\n",
    "                    # Optimize G\n",
    "                    for _ in range(k_g):\n",
    "                        # Sample noise\n",
    "                        noise = torch.Tensor(sample_noise(len(input_data), hyper_params['NOISE_DIM'])).to(device)\n",
    "\n",
    "                        # Do an update\n",
    "                        data_gen = generator(noise, inputs_batch)\n",
    "                        if INSTANCE_NOISE:\n",
    "                            data_gen += torch.distributions.Normal(0, hyper_params['INST_NOISE_STD']).\\\n",
    "                                        sample(data_gen.shape).to(device)\n",
    "                        loss = gan_losses.g_loss(discriminator(data_gen, inputs_batch))\n",
    "                        g_optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        g_optimizer.step()\n",
    "                    gen_epoch_loss.append(loss.item())\n",
    "                \n",
    "                experiment.log_metric(\"d_loss\", np.mean(dis_epoch_loss), step=epoch)\n",
    "                experiment.log_metric(\"g_loss\", np.mean(gen_epoch_loss), step=epoch)\n",
    "                \n",
    "                \n",
    "                if epoch % 20 == 0:\n",
    "                    f = draw_hitmap(n_samples=2000)\n",
    "                    experiment.log_figure(\"hitmap_{}\".format(epoch), f)\n",
    "                    plt.close(f)\n",
    "                    \n",
    "                    \n",
    "                    torch.save({\n",
    "                        'gen_state_dict': generator.state_dict(),\n",
    "                        'dis_state_dict': discriminator.state_dict(),\n",
    "                        'genopt_state_dict': g_optimizer.state_dict(),\n",
    "                        'disopt_state_dict': d_optimizer.state_dict(),\n",
    "                        'epoch': epoch\n",
    "                        }, PATH)\n",
    "                    experiment.log_asset(PATH, overwrite=True)\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
