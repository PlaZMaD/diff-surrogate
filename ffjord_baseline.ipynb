{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.52) detected. current: 1.0.53 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/schattengenie/diff-sim-ffjord/b4fee6d057524b5785c2cc643b965b72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "from comet_ml import API\n",
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment('HU8yNOX96Ang8huavKsvrTbiK', project_name=\"diff_sim_ffjord\", workspace=\"schattengenie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import YModel, R\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovering conditional density with FFJORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('./ffjord/')\n",
    "import ffjord.lib.utils as utils\n",
    "from ffjord.lib.visualize_flow import visualize_transform\n",
    "import ffjord.lib.layers.odefunc as odefunc\n",
    "from ffjord.train_misc import standard_normal_logprob\n",
    "from ffjord.train_misc import count_nfe, count_parameters, count_total_time\n",
    "from ffjord.train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
    "from ffjord.train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
    "from ffjord.train_misc import build_model_tabular\n",
    "import lib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tanh': Tanh(), 'relu': ReLU(), 'softplus': Softplus(beta=1, threshold=20), 'elu': ELU(alpha=1.0), 'swish': Swish(), 'square': Lambda(), 'identity': Lambda()}\n"
     ]
    }
   ],
   "source": [
    "SOLVERS = [\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams', 'fixed_adams']\n",
    "\n",
    "print(odefunc.NONLINEARITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cnf_options(model, solver, rademacher, residual, atol=1e-5, rtol=1e-5):\n",
    "\n",
    "    def _set(module):\n",
    "        if isinstance(module, layers.CNF):\n",
    "            # Set training settings\n",
    "            module.solver = solver\n",
    "            module.atol = atol\n",
    "            module.rtol = rtol\n",
    "\n",
    "            # If using fixed-grid adams, restrict order to not be too high.\n",
    "            if solver in ['fixed_adams', 'explicit_adams']:\n",
    "                module.solver_options['max_order'] = 4\n",
    "\n",
    "        if isinstance(module, layers.ODEfunc):\n",
    "            module.rademacher = rademacher\n",
    "            module.residual = residual\n",
    "\n",
    "    model.apply(_set)\n",
    "    \n",
    "# layer_type - [\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
    "def build_model_tabular(dims=2,\n",
    "                        layer_type='concatsquash', \n",
    "                        nonlinearity='relu', \n",
    "                        residual=False, \n",
    "                        rademacher=False,\n",
    "                        train_T=True,\n",
    "                        solver='dopri5',\n",
    "                        time_length=0.1,\n",
    "                        divergence_fn='brute_force', # [\"brute_force\", \"approximate\"]\n",
    "                        hidden_dims=(32, 32), \n",
    "                        num_blocks=1, batch_norm=False, \n",
    "                        bn_lag=0, regularization_fns=None):\n",
    "\n",
    "\n",
    "    def build_cnf():\n",
    "        diffeq = layers.ODEnet(\n",
    "            hidden_dims=hidden_dims,\n",
    "            input_shape=(dims,),\n",
    "            strides=None,\n",
    "            conv=False,\n",
    "            layer_type=layer_type,\n",
    "            nonlinearity=nonlinearity,\n",
    "        )\n",
    "        odefunc = layers.ODEfunc(\n",
    "            diffeq=diffeq,\n",
    "            divergence_fn=divergence_fn,\n",
    "            residual=residual,\n",
    "            rademacher=rademacher,\n",
    "        )\n",
    "        cnf = layers.CNF(\n",
    "            odefunc=odefunc,\n",
    "            T=time_length,\n",
    "            train_T=train_T,\n",
    "            regularization_fns=regularization_fns,\n",
    "            solver=solver,\n",
    "        )\n",
    "        return cnf\n",
    "\n",
    "    chain = [build_cnf() for _ in range(num_blocks)]\n",
    "    if batch_norm:\n",
    "        bn_layers = [layers.MovingBatchNorm1d(dims, bn_lag=bn_lag) for _ in range(num_blocks)]\n",
    "        bn_chain = [layers.MovingBatchNorm1d(dims, bn_lag=bn_lag)]\n",
    "        for a, b in zip(chain, bn_layers):\n",
    "            bn_chain.append(a)\n",
    "            bn_chain.append(b)\n",
    "        chain = bn_chain\n",
    "    model = layers.SequentialFlow(chain)\n",
    "\n",
    "    set_cnf_options(model, solver, rademacher, residual)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffjord.lib.layers.wrappers.cnf_regularization as reg_lib\n",
    "import six\n",
    "\n",
    "REGULARIZATION_FNS = {\n",
    "    \"l1int\": reg_lib.l1_regularzation_fn,\n",
    "    \"l2int\": reg_lib.l2_regularzation_fn,\n",
    "    \"dl2int\": reg_lib.directional_l2_regularization_fn,\n",
    "    \"JFrobint\": reg_lib.jacobian_frobenius_regularization_fn,\n",
    "    \"JdiagFrobint\": reg_lib.jacobian_diag_frobenius_regularization_fn,\n",
    "    \"JoffdiagFrobint\": reg_lib.jacobian_offdiag_frobenius_regularization_fn,\n",
    "}\n",
    "\n",
    "def create_regularization_fns(regs={'l1int': 1., 'JFrobint': 1.}):\n",
    "    regularization_fns = []\n",
    "    regularization_coeffs = []\n",
    "\n",
    "    for arg_key, reg_fn in six.iteritems(REGULARIZATION_FNS):\n",
    "        if arg_key in regs:\n",
    "            regularization_fns.append(reg_fn)\n",
    "            regularization_coeffs.append(regs[arg_key])\n",
    "\n",
    "    regularization_fns = tuple(regularization_fns)\n",
    "    regularization_coeffs = tuple(regularization_coeffs)\n",
    "    return regularization_fns, regularization_coeffs\n",
    "\n",
    "\n",
    "def get_regularization(model, regularization_coeffs):\n",
    "    if len(regularization_coeffs) == 0:\n",
    "        return None\n",
    "\n",
    "    acc_reg_states = tuple([0.] * len(regularization_coeffs))\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, layers.CNF):\n",
    "            acc_reg_states = tuple(acc + reg for acc, reg in zip(acc_reg_states, module.get_regularization_states()))\n",
    "    return acc_reg_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(model):\n",
    "\n",
    "    def sample_fn(z, logpz=None):\n",
    "        if logpz is not None:\n",
    "            return model(z, logpz, reverse=True)\n",
    "        else:\n",
    "            return model(z, reverse=True)\n",
    "\n",
    "    def density_fn(x, logpx=None):\n",
    "        if logpx is not None:\n",
    "            return model(x, logpx, reverse=False)\n",
    "        else:\n",
    "            return model(x, reverse=False)\n",
    "\n",
    "    return sample_fn, density_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def standard_normal_logprob(z, data):\n",
    "    logZ = -0.5 * math.log(2 * math.pi)\n",
    "    data_ref = torch.stack([torch.zeros(len(data)).to(data.device), \n",
    "                            data[:, 1],\n",
    "                            data[:, 2]], dim=1).float()\n",
    "    zpow = (z - data_ref).pow(2)\n",
    "    sigmas = torch.tensor([1., 1., 1.]).float().to(data.device)\n",
    "    return logZ - zpow / 2 / sigmas\n",
    "\n",
    "\n",
    "def compute_loss(model, data, batch_size=None):\n",
    "    # load data\n",
    "    #x = sample_data(data, batch_size=batch_size)\n",
    "    #x = torch.from_numpy(x).float().to(device)\n",
    "    # zero = torch.stack([torch.zeros(data.shape[0]).to(data.device), data[:, 1], data[:, 2]], dim=1).float()\n",
    "    zero = torch.zeros(data.shape[0], 1).to(data.device)\n",
    "    # print(zero.shape)\n",
    "    # transform to z\n",
    "    #zero[:, 2] = data[:, 2].detach()\n",
    "    z, delta_logp = model(data, zero)\n",
    "\n",
    "    # compute log q(z)\n",
    "    logpz = standard_normal_logprob(z, data).sum(1, keepdim=True)\n",
    "\n",
    "    logpx = logpz - delta_logp\n",
    "    loss = -torch.mean(logpx)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "y_sampler = YModel()\n",
    "mu_range = (-30, 30)\n",
    "mus = ((mu_range[0] - mu_range[1]) * (torch.rand(n_samples)) + mu_range[1]).to(device)\n",
    "xs = y_sampler.x_dist.sample([n_samples]).to(device)\n",
    "y_sampler.make_condition_sample({'mu': mus, 'X':xs})\n",
    "data = y_sampler.condition_sample().detach().to(device)\n",
    "data = torch.stack([data, mus, xs]).detach().t().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization is not very stable so should be optimized..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining FFJORD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_fns = None\n",
    "#regularization_fns, regularization_coeffs = create_regularization_fns()\n",
    "model = build_model_tabular(dims=3, \n",
    "                            num_blocks=1, \n",
    "                            hidden_dims=(32, 32), bn_lag=0.1,\n",
    "                            regularization_fns=regularization_fns).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-1, weight_decay=1e-5)\n",
    "\n",
    "loss_meter = utils.RunningAverageMeter(0.5)\n",
    "nfef_meter = utils.RunningAverageMeter(0.5)\n",
    "nfeb_meter = utils.RunningAverageMeter(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 40/40 [01:40<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4123107800894825 443.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train();\n",
    "for i in tqdm(range(40)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = compute_loss(model, data)\n",
    "\n",
    "    loss_meter.update(loss.item())\n",
    "    # nfe_forward = count_nfe(model)\n",
    "\n",
    "    loss.backward()\n",
    "    # clip_grad_norm(model.parameters(), 5)\n",
    "    optimizer.step()\n",
    "    if loss.item() < 4:\n",
    "        break\n",
    "    nfe_total = count_nfe(model)\n",
    "    # nfe_backward = nfe_total - nfe_forward\n",
    "    # nfef_meter.update(nfe_forward)\n",
    "    # nfeb_meter.update(nfe_backward)\n",
    "    clear_output()\n",
    "    print(loss_meter.avg, nfe_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-5)\n",
    "\n",
    "loss_meter = utils.RunningAverageMeter(0.5)\n",
    "nfef_meter = utils.RunningAverageMeter(0.5)\n",
    "nfeb_meter = utils.RunningAverageMeter(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 282/300 [10:51<00:32,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5588610951504185 269.0\n"
     ]
    }
   ],
   "source": [
    "model.train();\n",
    "for i in tqdm(range(300)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = compute_loss(model, data)\n",
    "\n",
    "    loss_meter.update(loss.item())\n",
    "    # nfe_forward = count_nfe(model)\n",
    "\n",
    "    loss.backward()\n",
    "    # clip_grad_norm(model.parameters(), 5)\n",
    "    optimizer.step()\n",
    "    #if loss.item() < 4:\n",
    "    #    break\n",
    "    nfe_total = count_nfe(model)\n",
    "    # nfe_backward = nfe_total - nfe_forward\n",
    "    # nfef_meter.update(nfe_forward)\n",
    "    # nfeb_meter.update(nfe_backward)\n",
    "    clear_output()\n",
    "    print(loss_meter.avg, nfe_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fn, density_fn = get_transforms(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on mu outside of training domain\n",
    "\n",
    "It was trained on $\\mu \\in [ -30: 30]$ and evaluated on $\\mu \\in [ -60: 60]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(21,16))\n",
    "mu_range = list(range(-60, 60, 2))\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        plt.subplot(4,3, i*3 + j + 1)\n",
    "        input_mu = torch.full(size=(10000, ), fill_value=mu_range[::len(mu_range) // 12][i * 3 + j])#.to(device)\n",
    "        input_x = y_sampler.x_dist.sample(input_mu.shape).to(device)\n",
    "\n",
    "        y_sampler.make_condition_sample({'mu': input_mu})\n",
    "        data = y_sampler.condition_sample()\n",
    "\n",
    "        input_mu = input_mu.to(device)\n",
    "\n",
    "        \n",
    "        data_ref = torch.stack([0.1 * torch.randn(len(input_mu)).to(device), \n",
    "                                input_mu, input_x], dim=1).float()\n",
    "        sampled = sample_fn(data_ref)\n",
    "        \n",
    "        \n",
    "        plt.hist(data, bins=100, normed=True, label='true');\n",
    "        plt.hist(sampled[:, 0].detach().cpu().numpy(),\n",
    "             bins=100, color='g', density=True, alpha=0.5, label='ffjord');\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(\"mu={:.3f}\".format(input_mu[0].item()))\n",
    "        \n",
    "experiment.log_figure(figure_name=\"FFJOR evaluation\", figure=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_calc = Metrics((-50, 50), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(21,16))\n",
    "mu_range = list(range(-60, 60, 2))\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        mu = mu_range[::len(mu_range) // 12][i * 3 + j]\n",
    "        input_mu = torch.full(size=(10000, ), fill_value=mu_range[::len(mu_range) // 12][i * 3 + j])#.to(device)\n",
    "        input_x = y_sampler.x_dist.sample(input_mu.shape).to(device)\n",
    "\n",
    "        y_sampler.make_condition_sample({'mu': input_mu})\n",
    "        data = y_sampler.condition_sample()\n",
    "\n",
    "        input_mu = input_mu.to(device)\n",
    "\n",
    "        \n",
    "        data_ref = torch.stack([0.1 * torch.randn(len(input_mu)).to(device), \n",
    "                                input_mu, input_x], dim=1).float()\n",
    "        sampled = sample_fn(data_ref)\n",
    "        \n",
    "        w_dist = wasserstein_distance(sampled[:, 0].detach().cpu().numpy(), data.detach().cpu().numpy())\n",
    "        experiment.log_metric('wasserstein_distance_mu={}'.format(mu), w_dist)\n",
    "        \n",
    "        for order in [1, 2]:\n",
    "            diff = metric_calc.compute_moment(sampled[:, 0].cpu().detach(), order=order) - metric_calc.compute_moment(data.cpu().detach(), order=order)\n",
    "            experiment.log_metric('moment_diff_mu={},order={}'.format(mu, order), diff)\n",
    "        \n",
    "        js = metric_calc.compute_JS(sampled[:, 0].cpu(), data.cpu())\n",
    "        kl = metric_calc.compute_KL(sampled[:, 0].cpu(), data.cpu())\n",
    "        ksstat = metric_calc.compute_KSStat(sampled[:, 0].cpu().detach(), data.cpu().detach())\n",
    "        \n",
    "        experiment.log_metric('JS_mu={}'.format(mu), js)\n",
    "        experiment.log_metric('KL_mu={}'.format(mu), kl)\n",
    "        experiment.log_metric('KS_mu={}'.format(mu), ksstat)\n",
    "        print(mu, w_dist, js, kl, ksstat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def standard_normal_logprob_for_sampling(z, data):\n",
    "    logZ = -0.5 * math.log(2 * math.pi)\n",
    "    data_ref = torch.stack([torch.zeros(len(data)).to(data.device), \n",
    "                            data[:, 1],\n",
    "                            data[:, 2]], dim=1).float()\n",
    "    zpow = (z - data_ref).pow(2)\n",
    "    sigmas = torch.tensor([1., 1., 1.]).float().to(data.device)\n",
    "    return logZ - zpow / 2 / sigmas\n",
    "\n",
    "\n",
    "def exp_normalize(x):\n",
    "    b = x.max()\n",
    "    y = np.exp(x - b)\n",
    "    return y / y.sum()\n",
    "\n",
    "def proba_fn(data_ref, density_fn):\n",
    "    zero_ref = torch.stack([torch.zeros(len(data_ref)).to(device), \n",
    "                            data_ref[:, 1],\n",
    "                            data_ref[:, 2]], dim=1).float()\n",
    "    z, delta_logp = density_fn(data_ref, zero_ref)\n",
    "    logpz = standard_normal_logprob_for_sampling(z, data_ref)\n",
    "    logpx = logpz - delta_logp\n",
    "    \n",
    "    yhat = savgol_filter(logpx.sum(dim=1).detach().cpu().numpy(), 21, 3)\n",
    "    proba = exp_normalize(yhat)\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 16))\n",
    "mu_range = list(range(22, 60, 2))\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        plt.subplot(4, 3, i*3 + j + 1)\n",
    "        input_mu = torch.full(size=(100, ), fill_value=mu_range[i*3 + j])#.to(device)\n",
    "        input_x = y_sampler.x_dist.sample(input_mu.shape).to(device)\n",
    "\n",
    "        y_sampler.make_condition_sample({'mu': input_mu})\n",
    "        data = y_sampler.condition_sample().detach().cpu().numpy()\n",
    "\n",
    "        input_mu = input_mu.to(device)\n",
    "\n",
    "        ref = torch.linspace(10, 70, len(input_mu)).float().to(device)\n",
    "        data_ref = torch.stack([ref, input_mu, input_x], dim=1).float()\n",
    "        proba = proba_fn(data_ref, density_fn)\n",
    "        plt.hist(data, bins=100, normed=True, label='true');\n",
    "        plt.plot(ref.detach().cpu().numpy(), proba / (ref[1] - ref[0]).item(), color='g', alpha=0.5, label='ffjord');\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.title(\"mu={:.3f}\".format(input_mu[0].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "sample_size = 5\n",
    "\n",
    "\n",
    "mu_optim = torch.tensor(30.)\n",
    "mu_optim = mu_optim.repeat(sample_size).to(device)\n",
    "mu_optim.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 722/3000 [21:47<1:14:54,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 -6.486995220184326\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_iter = 3000\n",
    "losses = []\n",
    "m_vals = []\n",
    "for _iter in tqdm(range(n_iter)):    \n",
    "    x = y_sampler.x_dist.sample([mu_optim.shape[0]]).to(device)\n",
    "    # Do an update    \n",
    "    data_ref = torch.stack([torch.randn(len(mu_optim)).to(device), \n",
    "                            mu_optim, x], dim=1).float()\n",
    "    sampled = sample_fn(data_ref)\n",
    "    \n",
    "    loss = R(sampled[:, 0])\n",
    "    losses.append(loss.item())\n",
    "    if mu_optim.grad is not None: mu_optim.grad.zero_()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        mu_optim -= lr * mu_optim.grad.mean()\n",
    "        mu_optim.grad.zero_()\n",
    "    m_vals.append(mu_optim[0].item())\n",
    "    clear_output()\n",
    "    \n",
    "    print(_iter, mu_optim[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(losses);\n",
    "plt.grid()\n",
    "plt.ylabel(\"Loss\", fontsize=19)\n",
    "plt.xlabel(\"iter\", fontsize=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(m_vals);\n",
    "plt.grid()\n",
    "plt.ylabel(\"$\\mu$\", fontsize=19)\n",
    "plt.xlabel(\"iter\", fontsize=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
